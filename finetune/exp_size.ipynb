{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from loader import H5ImageLoader\n",
    "import os\n",
    "from decoder import LightDecoder\n",
    "from encoder import SparseEncoder\n",
    "from network import build_sparse_encoder\n",
    "from spark import SparK\n",
    "from loss import DiceLoss\n",
    "import torch.distributed as dist\n",
    "import data\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variables for distributed training\n",
    "os.environ['MASTER_ADDR'] = 'localhost'  # or another appropriate address\n",
    "os.environ['MASTER_PORT'] = '12355'  # choose an open port\n",
    "\n",
    "# Initialise distribute for single GPU training\n",
    "dist.init_process_group(backend='nccl', init_method='env://', rank=0, world_size=1)\n",
    "\n",
    "# Specify the device to use\n",
    "USING_GPU_IF_AVAILABLE = True\n",
    "\n",
    "ir_ = torch.empty(1)\n",
    "if torch.cuda.is_available() and USING_GPU_IF_AVAILABLE:\n",
    "    ir_ = ir_.cuda()\n",
    "DEVICE = ir_.device\n",
    "print(f'[DEVICE={DEVICE}]')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DATA_PATH = './data'\n",
    "\n",
    "## Training parameters\n",
    "minibatch_size = 8\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 50\n",
    "criterion = DiceLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_spark(your_own_pretrained_ckpt: str):\n",
    "        \n",
    "    input_size, model_name = 224, 'resnet50'\n",
    "    pretrained_state = torch.load(your_own_pretrained_ckpt, map_location='cpu')\n",
    "    print(f\"[in function `build_spark`] your ckpt `{your_own_pretrained_ckpt}` loaded\")\n",
    "\n",
    "    # Build a SparK model\n",
    "    #print(pretrained_state.keys())\n",
    "    enc: SparseEncoder = build_sparse_encoder(model_name, input_size=input_size)\n",
    "    spark = SparK(\n",
    "        sparse_encoder=enc, \n",
    "        dense_decoder=LightDecoder(enc.downsample_raito, sbn=False)\n",
    "        ).to(DEVICE)\n",
    "    spark.eval(), [p.requires_grad_(False) for p in spark.parameters()]\n",
    "\n",
    "    # Adjusting loading to handle incompatible keys\n",
    "    pretrained_dict = pretrained_state\n",
    "    model_dict = spark.state_dict()\n",
    "\n",
    "    # Filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and model_dict[k].size() == v.size()}\n",
    "    # Overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    \n",
    "    # Load the checkpoint\n",
    "    missing, unexpected = spark.load_state_dict(model_dict, strict=False)\n",
    "    assert len(missing) == 0, f'load_state_dict missing keys: {missing}'\n",
    "    assert len(unexpected) == 0, f'load_state_dict unexpected keys: {unexpected}'\n",
    "    del pretrained_state\n",
    "    return spark\n",
    "\n",
    "def pre_process(images, labels):\n",
    "    # Convert each numpy array in `images` to a PyTorch tensor and stack\n",
    "    images = torch.stack([torch.tensor(img).float() for img in images])\n",
    "    # Similarly, ensure labels are tensors, then stack and add an extra dimension\n",
    "    labels = torch.stack([torch.tensor(lbl).unsqueeze(-1).float() for lbl in labels])\n",
    "    return images, labels\n",
    "\n",
    "def validate_and_test(model, loader, criterion, device, ratio_train, vis):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    total_batches = 0\n",
    "    total_correct_pixels = 0\n",
    "    total_pixels = 0\n",
    "    \n",
    "    with torch.no_grad():  # No gradients needed\n",
    "        for images, masks in loader:\n",
    "            images, masks = pre_process(images, masks)\n",
    "            images = images.permute(0, 3, 1, 2).to(device)\n",
    "            masks = masks.permute(0, 3, 1, 2).to(device)\n",
    "            outputs = model(images, active_b1ff=None)\n",
    "            outputs = outputs.sigmoid() \n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion.dice_loss(outputs, masks)\n",
    "            loss = loss.mean()\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predicted_masks = (outputs > 0.5).float()  # threshold of 0.5 for binarization\n",
    "            correct_pixels = torch.sum(predicted_masks == masks).item()\n",
    "            total_correct_pixels += correct_pixels\n",
    "            total_pixels += torch.numel(masks)\n",
    "            \n",
    "            total_batches += 1\n",
    "    \n",
    "    avg_loss = val_loss / total_batches \n",
    "    accuracy = total_correct_pixels / total_pixels * 100\n",
    "    model.train() # Put the model back to train mode\n",
    "\n",
    "    if vis:\n",
    "        visualize_images_outputs_and_masks(images, outputs, masks, ratio_train)\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def concatenate_images(image_list):\n",
    "    widths, heights = zip(*(i.size for i in image_list))\n",
    "    total_height = sum(heights)\n",
    "    max_width = max(widths)\n",
    "\n",
    "    new_im = Image.new('RGB', (max_width, total_height))\n",
    "\n",
    "    y_offset = 0\n",
    "    for im in image_list:\n",
    "        new_im.paste(im, (0, y_offset))\n",
    "        y_offset += im.size[1]\n",
    "\n",
    "    return new_im\n",
    "\n",
    "def visualize_testing(model, loader, device, ratio_train):\n",
    "    model.eval()\n",
    "    images, masks = next(iter(loader))  # Get a batch from the loader\n",
    "    images, masks = pre_process(images, masks)\n",
    "    images = images.permute(0, 3, 1, 2).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(images, active_b1ff=None)\n",
    "    preds = preds.sigmoid().cpu()\n",
    "\n",
    "    # Plotting\n",
    "    visualize_images_outputs_and_masks(images, preds, masks, ratio_train)\n",
    "\n",
    "    \n",
    "def visualize_images_outputs_and_masks(images, outputs, masks, ratio_train, num_images=minibatch_size):\n",
    "\n",
    "    # Post-process outputs\n",
    "    outputs = post_process(outputs)\n",
    "\n",
    "    # Ensure images, outputs, and masks are tensor type and check dimensions\n",
    "    if not (images.ndim == 4 and outputs.ndim in [3, 4] and masks.ndim in [3, 4]):\n",
    "        raise ValueError(\"Invalid input dimensions\")\n",
    "\n",
    "    # permute images from BxCxHxW to BxHxWxC for matplotlib\n",
    "    images = images.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "\n",
    "    # Prepare outputs and masks (handle both cases where outputs and masks might have an extra channel dimension)\n",
    "    outputs = outputs.squeeze(1).cpu().detach().numpy() if outputs.ndim == 4 else outputs.cpu().detach().numpy()\n",
    "    masks = masks.squeeze(1).cpu().detach().numpy() if masks.ndim == 4 else masks.cpu().detach().numpy()\n",
    "\n",
    "    # Normalize and convert to uint8\n",
    "    for i in range(num_images):\n",
    "        img = ((images[i] - images[i].min()) / (images[i].max() - images[i].min()) * 255).astype(np.uint8)\n",
    "        out = (outputs[i] * 255).astype(np.uint8)\n",
    "        msk = (masks[i] * 255).astype(np.uint8)\n",
    "\n",
    "        pil_img = Image.fromarray(img, 'RGB')\n",
    "        pil_out = Image.fromarray(out, 'L').convert('RGB')\n",
    "        pil_msk = Image.fromarray(msk, 'L').convert('RGB')\n",
    "\n",
    "        # Combine images vertically\n",
    "        combined_image = concatenate_images([pil_img, pil_out, pil_msk])\n",
    "        # Save the image\n",
    "        combined_image.save(f\"exp_img/result_{i}_{ratio_train}.png\")\n",
    "\n",
    "\n",
    "def post_process(output):\n",
    "  \n",
    "    threshold = 0.5\n",
    "    device = output.device  # Get the device of the output tensor\n",
    "    processed_output = torch.where(output > threshold, torch.tensor(1, device=device), torch.tensor(0, device=device))\n",
    "    return processed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model_path = \"models\"\n",
    "model_file = \"model_200epochs.pth\"\n",
    "model = build_spark(os.path.join(model_path, model_file)) #Change this to the path of your own pretrained model\n",
    "print(\"model built\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the list of ratio_train values\n",
    "ratio_trains = [0.55, 0.7, 0.85]\n",
    "\n",
    "# Create the 'exp_img' folder if it doesn't exist\n",
    "result_path = 'exp_img'\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "# Initialize lists to store the losses and accuracies for each ratio_train\n",
    "running_losses_all = []\n",
    "val_losses_all = []\n",
    "val_accuracies_all = []\n",
    "test_accuracies = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each item in the list and print it\n",
    "for ratio_train in ratio_trains:\n",
    "    print(\"Current training ratio: \", ratio_train)\n",
    "\n",
    "    # Prepare the dataset\n",
    "    data.prepare_dataset(ratio_train = ratio_train, split_data = True) # test set ratio is fixed at 10%\n",
    "    ## Data loader\n",
    "    loader_train = H5ImageLoader(DATA_PATH+'/images_train.h5', minibatch_size, DATA_PATH+'/labels_train.h5')\n",
    "    loader_val = H5ImageLoader(DATA_PATH+'/images_val.h5', 20, DATA_PATH+'/labels_val.h5')\n",
    "    loader_test = H5ImageLoader(DATA_PATH+'/images_test.h5', 20, DATA_PATH+'/labels_test.h5')\n",
    "    print(\"Dataset Loaded: num_train: %d, num_val: %d, num_test: %d\" % (loader_train.num_images, loader_val.num_images, loader_test.num_images))\n",
    "    \n",
    "    # Initialize lists to store the losses and accuracies of current ratio\n",
    "    val_losses = []\n",
    "    running_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Finetuning loop\n",
    "    print(\"start finetuning\")\n",
    "    for epoch in range(num_epochs): \n",
    "        model.train()\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad_(True)\n",
    "        running_loss = 0.0\n",
    "        batches_processed = 0\n",
    "        for images, masks in loader_train:\n",
    "\n",
    "            images, masks = pre_process(images, masks)\n",
    "            images = images.permute(0, 3, 1, 2)\n",
    "            masks = masks.permute(0, 3, 1, 2)\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, active_b1ff=None)  \n",
    "            outputs = torch.sigmoid(outputs) \n",
    "            loss = criterion.dice_loss(outputs, masks)\n",
    "            loss = loss.mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            batches_processed += 1\n",
    "\n",
    "            # Report the current average loss after every 500 images\n",
    "            # if batches_processed % 500 == 0:\n",
    "            #     print(f\"Processed {batches_processed} batches, Current Loss: {running_loss/batches_processed:.4f}\")\n",
    "            #     val_loss, val_accuracy = validate_and_test(model, loader_val, criterion, DEVICE, vis=False)\n",
    "            #     print(f\"Current Validation Loss: {val_loss}\")\n",
    "            #     print(f\"Current Validation Accuracy: {val_accuracy}%\")\n",
    "                \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/batches_processed}\")\n",
    "        val_loss, val_accuracy = validate_and_test(model, loader_val, criterion, DEVICE, ratio_train, vis=False)\n",
    "        # print(f\"Epoch {epoch+1}, Validation Loss: {val_loss}\")\n",
    "        print(f\"Epoch {epoch+1}, Validation Accuracy: {val_accuracy}%\")\n",
    "        # visualize_images_outputs_and_masks(images, outputs, masks)\n",
    "        running_losses.append(running_loss/batches_processed)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Test the model after training\n",
    "    test_loss, test_accuracy = validate_and_test(model, loader_test, criterion, DEVICE, ratio_train, vis=True)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    print(f\"Training finished.\\nTest Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")  \n",
    "\n",
    "    # Store the losses and accuracies for the current ratio_train\n",
    "    running_losses_all.append(running_losses)\n",
    "    val_losses_all.append(val_losses)\n",
    "    val_accuracies_all.append(val_accuracies)\n",
    "    \n",
    "    # Save the model\n",
    "    model_name = f\"best_model_{ratio_train}.pth\"\n",
    "    torch.save(model.state_dict(), os.path.join(model_path, model_name))\n",
    "    print(\"Model saved.\")\n",
    "\n",
    "    # Close the HDF5 files\n",
    "    loader_train.close()\n",
    "    loader_val.close()\n",
    "    loader_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure 1:   6 curves\n",
    "\n",
    "x axis: epoch\n",
    "y axis: running_losses_all[0], running_losses_all[1], running_losses_all[2]\n",
    "         val_losses_all[0], val_losses_all[1], val_losses_all[2]\n",
    "\n",
    "figure 2:   3 curves\n",
    "x axis: epoch\n",
    "y axis: val_accuracies_all[0], val_accuracies_all[1], val_accuracies_all[2]\n",
    "\n",
    "figure 3:   3 points connected as a curve\n",
    "x axis: ratio_train\n",
    "y axis: test_accuracies\n",
    "\n",
    "figure 4:   3 points connected as a curve\n",
    "x axis: ratio_train\n",
    "y axis: test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "# Configuration parameters\n",
    "width, height = 1000, 600\n",
    "padding = 50\n",
    "colors = [(51, 153, 255), (255, 102, 102), (153, 204, 0), (153, 51, 255), (255, 153, 0), (0, 153, 153)]  # Different colors for curves\n",
    "grid_color = (200, 200, 200)  # Light gray\n",
    "text_color = (0, 0, 0)  # Black\n",
    "\n",
    "# Load fonts\n",
    "try:\n",
    "    title_font = ImageFont.truetype(\"utils/Arial.ttf\", 24)\n",
    "    label_font = ImageFont.truetype(\"utils/Arial.ttf\", 14)\n",
    "except IOError:\n",
    "    title_font = ImageFont.load_default()\n",
    "    label_font = ImageFont.load_default()\n",
    "\n",
    "def draw_grid(draw, num_y_ticks, max_y_value, min_y_value, x_ticks):\n",
    "    # Y-axis grid lines and labels\n",
    "    for i in range(num_y_ticks + 1):\n",
    "        y = height - padding - i * (height - 2 * padding) / num_y_ticks\n",
    "        value = min_y_value + i * (max_y_value - min_y_value) / num_y_ticks\n",
    "        draw.line([(padding, y), (width - padding, y)], fill=grid_color)\n",
    "        draw.text((5, y - 10), f\"{value:.2f}\", font=label_font, fill=text_color)\n",
    "\n",
    "    # X-axis labels\n",
    "    for i, x_tick in enumerate(x_ticks):\n",
    "        x = padding + i * (width - 2 * padding) // (len(x_ticks) - 1)\n",
    "        draw.text((x - 10, height - padding + 10), str(x_tick), font=label_font, fill=text_color)\n",
    "\n",
    "def plot_curves(data_sets, labels, colors, title, x_ticks, x_label, y_label, y_legend, results_path='exp_img'):\n",
    "    img = Image.new('RGB', (width, height + len(labels) * 20), 'white')  # Extra space for legends\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    max_value = max(max(data) for data in data_sets)\n",
    "    min_value = min(min(data) for data in data_sets)\n",
    "    draw_grid(draw, 5, max_value, min_value, x_ticks)\n",
    "\n",
    "    for data, color in zip(data_sets, colors):\n",
    "        draw_data(draw, data, color, max_value, min_value, x_ticks)\n",
    "\n",
    "    # Legend on the right side of the graph\n",
    "    legend_start_x = width - 300\n",
    "    legend_start_y = y_legend\n",
    "    for i, label in enumerate(labels):\n",
    "        draw.rectangle([(legend_start_x, legend_start_y + i * 20), (legend_start_x + 10, legend_start_y + 10 + i * 20)], fill=colors[i])\n",
    "        draw.text((legend_start_x + 15, legend_start_y + i * 20), label, fill='black', font=label_font)\n",
    "\n",
    "    # Text and labels\n",
    "    draw.text((width // 2 - 100, 10), title, font=title_font, fill=text_color)\n",
    "    draw.text((width / 2 - len(x_label) * 3, height - 20), x_label, font=label_font, fill=text_color)  # X label centered at the bottom\n",
    "    draw.text((10, 20), y_label, font=label_font, fill=text_color)\n",
    "\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    img.save(os.path.join(results_path, title.replace(' ', '_') + '.png'))\n",
    "\n",
    "def draw_data(draw, data, color, max_value, min_value, x_ticks):\n",
    "    prev_x = prev_y = None\n",
    "    for i, value in enumerate(data):\n",
    "        x = padding + i * (width - 2 * padding) // (len(x_ticks) - 1)\n",
    "        y = height - padding - (value - min_value) / (max_value - min_value) * (height - 2 * padding)\n",
    "        if prev_x is not None and prev_y is not None:\n",
    "            draw.line((prev_x, prev_y, x, y), fill=color, width=2)\n",
    "        draw.ellipse((x - 3, y - 3, x + 3, y + 3), fill=color)\n",
    "        prev_x, prev_y = x, y\n",
    "\n",
    "# Example data simulation\n",
    "epochs = list(range(1, num_epochs + 1))\n",
    "\n",
    "# running_losses_all = [[0.2 - 0.02*i for i in epochs], [0.4 - 0.03*i for i in epochs], [0.35 - 0.025*i for i in epochs]]\n",
    "# val_losses_all = [[0.25 - 0.015*i for i in epochs], [0.32 - 0.02*i for i in epochs], [0.3 - 0.02*i for i in epochs]]\n",
    "# val_accuracies_all = [[0.25 - 0.018*i for i in epochs], [0.22 - 0.02*i for i in epochs], [0.3 - 0.05*i for i in epochs]]\n",
    "# test_accuracies = [0.7, 0.777, 0.89]\n",
    "# test_losses = [0.67, 0.56, 0.34]\n",
    "\n",
    "# Create graphs\n",
    "plot_curves(running_losses_all + val_losses_all, \n",
    "            ['Training Loss, Trainset ratio = 0.55', 'Training Loss, Trainset ratio = 0.7', 'Training Loss, Trainset ratio = 0.85', 'Val Loss, Trainset ratio = 0.55', 'Val Loss, Trainset ratio = 0.7', 'Val Loss, Trainset ratio = 0.85'], \n",
    "            colors[:6], 'Losses over Epochs', epochs, 'Epoch', 'Loss', padding)\n",
    "plot_curves(val_accuracies_all, \n",
    "            ['Validation Accuracy, Trainset ratio = 0.55', 'Validation Accuracy, Trainset ratio = 0.7', 'Validation Accuracy, Trainset ratio = 0.85'], \n",
    "            colors[:3], 'Validation Accuracies over Epochs', epochs, 'Epoch', 'Accuracy (%)', 420)\n",
    "plot_curves([test_accuracies], \n",
    "            ['Test Accuracy'], \n",
    "            [colors[0]], 'Test Accuracies over Training Ratio', ratio_trains, 'Training Ratio', 'Accuracy (%)', padding)\n",
    "plot_curves([test_losses], \n",
    "            ['Test Loss'], \n",
    "            [colors[1]], 'Test Losses over Training Ratio', ratio_trains, 'Training Ratio', 'Loss', padding)\n",
    "print(\"test accuracy: \", test_accuracies)\n",
    "print(\"test_losses: \", test_losses)\n",
    "# Save test_accuracies and test_losses to a text file\n",
    "with open(os.path.join(result_path, 'test_results.txt'), 'w') as f:\n",
    "    f.write(f\"Training Losses 0.55: {running_losses_all[0]}\\n\")\n",
    "    f.write(f\"Training Losses 0.7: {running_losses_all[1]}\\n\")\n",
    "    f.write(f\"Training Losses 0.85: {running_losses_all[2]}\\n\")\n",
    "    f.write(f\"Validation Losses 0.55: {val_losses_all[0]}\\n\")\n",
    "    f.write(f\"Validation Losses 0.7: {val_losses_all[1]}\\n\")\n",
    "    f.write(f\"Validation Losses 0.85: {val_losses_all[2]}\\n\")\n",
    "    f.write(f\"Validation Accuracy 0.55: {val_accuracies_all[0]}\\n\")\n",
    "    f.write(f\"Validation Accuracy 0.7: {val_accuracies_all[1]}\\n\")\n",
    "    f.write(f\"Validation Accuracy 0.85: {val_accuracies_all[2]}\\n\")\n",
    "    f.write(f\"Test Accuracies: {test_accuracies}\\n\")\n",
    "    f.write(f\"Test Losses: {test_losses}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
